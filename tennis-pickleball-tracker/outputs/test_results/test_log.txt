============================= test session starts =============================
platform win32 -- Python 3.13.3, pytest-9.0.2, pluggy-1.6.0 -- C:\Python313\python.exe
cachedir: .pytest_cache
rootdir: D:\Downloads\cv\tennis-pickleball-tracker
plugins: anyio-3.7.1, langsmith-0.6.6
collecting ... collected 54 items

tests/test_pipeline_video.py::TestVideoLoading::test_video_exists PASSED
tests/test_pipeline_video.py::TestVideoLoading::test_video_opens PASSED
tests/test_pipeline_video.py::TestVideoLoading::test_video_metadata 
  Video: 1920x1080 @ 30.0fps, 1139 frames
PASSED
tests/test_pipeline_video.py::TestVideoLoading::test_read_first_frame PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_import PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_classical_detector_init PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_preprocess 
  White pixel %: 10.73%
PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_detect_edges 
  Edge pixel %: 1.75%
PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_detect_lines 
  Detected 191 lines
PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_full_detect 
  Horizontal lines: 4
  Vertical lines: 4
  Intersections: 16
PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_detect_and_compute_homography 
  Homography computation failed (may happen with some videos)
PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_transform_point PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_transform_points PASSED
tests/test_pipeline_video.py::TestCourtDetection::test_court_constants PASSED
tests/test_pipeline_video.py::TestObjectDetection::test_import PASSED
tests/test_pipeline_video.py::TestObjectDetection::test_detection_dataclass PASSED
tests/test_pipeline_video.py::TestObjectDetection::test_yolo_init FAILED
tests/test_pipeline_video.py::TestObjectDetection::test_yolo_detect_on_frame FAILED
tests/test_pipeline_video.py::TestObjectDetection::test_nms 
  NMS: 3 -> 2 detections
PASSED
tests/test_pipeline_video.py::TestObjectDetection::test_classical_ball_detector 
  Classical ball detections: 4
PASSED
tests/test_pipeline_video.py::TestObjectDetection::test_classical_player_detector FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_import FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_init FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_update_with_measurement FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_update_without_measurement FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_trajectory FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_optical_flow_estimator FAILED
tests/test_pipeline_video.py::TestObjectTracking::test_multi_object_tracker_no_deepsort FAILED
tests/test_pipeline_video.py::TestTrajectory3D::test_import PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_trajectory_point PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_bounce_event PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_trajectory_3d PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_court_projector PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_court_projector_roundtrip PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_physics_model_init PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_in_out_classifier_singles PASSED
tests/test_pipeline_video.py::TestTrajectory3D::test_in_out_classifier_with_confidence 
  Near-line: is_in=True, confidence=1.000
  Center: is_in=True, confidence=1.000
PASSED
tests/test_pipeline_video.py::TestInOutClassifierModule::test_import PASSED
tests/test_pipeline_video.py::TestInOutClassifierModule::test_ml_bounce_classifier_init PASSED
tests/test_pipeline_video.py::TestInOutClassifierModule::test_enhanced_system_init PASSED
tests/test_pipeline_video.py::TestVisualization::test_import PASSED
tests/test_pipeline_video.py::TestVisualization::test_frame_annotator_init PASSED
tests/test_pipeline_video.py::TestVisualization::test_draw_detections PASSED
tests/test_pipeline_video.py::TestVisualization::test_draw_ball_trajectory PASSED
tests/test_pipeline_video.py::TestVisualization::test_minimap_tennis 
  MiniMap size: (600, 300, 3)
PASSED
tests/test_pipeline_video.py::TestVisualization::test_minimap_pickleball PASSED
tests/test_pipeline_video.py::TestVisualization::test_heatmap_generator FAILED
tests/test_pipeline_video.py::TestVisualization::test_composite_frame_builder 
  Composite frame size: (360, 760, 3)
PASSED
tests/test_pipeline_video.py::TestEndToEndPipeline::test_pipeline_import FAILED
tests/test_pipeline_video.py::TestEndToEndPipeline::test_pipeline_short_run FAILED
tests/test_pipeline_video.py::TestEndToEndPipeline::test_pipeline_100_frames FAILED
tests/test_pipeline_video.py::TestIntegration::test_court_detection_to_classification PASSED
tests/test_pipeline_video.py::TestIntegration::test_detection_to_tracking FAILED
tests/test_pipeline_video.py::TestIntegration::test_visualization_with_real_detections FAILED

================================== FAILURES ===================================
_____________________ TestObjectDetection.test_yolo_init ______________________

self = <test_pipeline_video.TestObjectDetection object at 0x000001E0BF8156E0>

    def test_yolo_init(self):
        from object_detection import YOLODetector
>       detector = YOLODetector(model_path="yolov8n.pt", device="cpu")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:235: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_detection.YOLODetector object at 0x000001E0C5E1D550>
model_path = 'yolov8n.pt', conf_threshold = 0.25, iou_threshold = 0.45
device = 'cpu', classes = None

    def __init__(
        self,
        model_path: str = "yolov8s.pt",
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45,
        device: str = "0",
        classes: Optional[List[int]] = None,
    ):
        """
        Args:
            model_path: Path to YOLOv8 weights (.pt file)
            conf_threshold: Minimum confidence for detections
            iou_threshold: NMS IoU threshold
            device: CUDA device ("0") or "cpu"
            classes: List of class indices to detect (None = all)
        """
        try:
            from ultralytics import YOLO
>           self.model = YOLO(model_path)
                         ^^^^^^^^^^^^^^^^

src\object_detection.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), model = 'yolov8n.pt', task = None

    def __init__(self, model: Union[str, Path] = 'yolov8n.pt', task=None) -> None:
        """
        Initializes the YOLO model.
    
        Args:
            model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to 'yolov8n.pt'.
            task (Any, optional): Task type for the YOLO model. Defaults to None.
        """
        super().__init__()
        self.callbacks = callbacks.get_default_callbacks()
        self.predictor = None  # reuse predictor
        self.model = None  # model object
        self.trainer = None  # trainer object
        self.ckpt = None  # if loaded from *.pt
        self.cfg = None  # if loaded from *.yaml
        self.ckpt_path = None
        self.overrides = {}  # overrides for trainer object
        self.metrics = None  # validation/training metrics
        self.session = None  # HUB session
        self.task = task  # task type
        model = str(model).strip()  # strip spaces
    
        # Check if Ultralytics HUB model from https://hub.ultralytics.com
        if self.is_hub_model(model):
            from ultralytics.hub.session import HUBTrainingSession
            self.session = HUBTrainingSession(model)
            model = self.session.model_file
    
        # Check if Triton Server model
        elif self.is_triton_model(model):
            self.model = model
            self.task = task
            return
    
        # Load or create new YOLO model
        suffix = Path(model).suffix
        if not suffix and Path(model).stem in GITHUB_ASSETS_STEMS:
            model, suffix = Path(model).with_suffix('.pt'), '.pt'  # add suffix, i.e. yolov8n -> yolov8n.pt
        if suffix in ('.yaml', '.yml'):
            self._new(model, task)
        else:
>           self._load(model, task)

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), weights = 'yolov8n.pt', task = None

    def _load(self, weights: str, task=None):
        """
        Initializes a new model and infers the task type from the model head.
    
        Args:
            weights (str): model checkpoint to be loaded
            task (str | None): model task
        """
        suffix = Path(weights).suffix
        if suffix == '.pt':
>           self.model, self.ckpt = attempt_load_one_weight(weights)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt', device = None, inplace = True, fuse = False

    def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):
        """Loads a single model weights."""
>       ckpt, weight = torch_safe_load(weight)  # load ckpt
                       ^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:628: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt'

    def torch_safe_load(weight):
        """
        This function attempts to load a PyTorch model with the torch.load() function. If a ModuleNotFoundError is raised,
        it catches the error, logs a warning message, and attempts to install the missing module via the
        check_requirements() function. After installation, the function again attempts to load the model using torch.load().
    
        Args:
            weight (str): The file path of the PyTorch model.
    
        Returns:
            (dict): The loaded PyTorch model.
        """
        from ultralytics.utils.downloads import attempt_download_asset
    
        check_suffix(file=weight, suffix='.pt')
        file = attempt_download_asset(weight)  # search online if missing locally
        try:
            with temporary_modules({
                    'ultralytics.yolo.utils': 'ultralytics.utils',
                    'ultralytics.yolo.v8': 'ultralytics.models.yolo',
                    'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models
>               return torch.load(file, map_location='cpu'), file  # load
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:567: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

f = 'yolov8n.pt', map_location = 'cpu', pickle_module = None
weights_only = True, mmap = False, pickle_load_args = {'encoding': 'utf-8'}
_get_wo_message = <function load.<locals>._get_wo_message at 0x000001E0C5E67880>
weights_only_not_set = True, true_values = ['1', 'y', 'yes', 'true']
force_weights_only_load = False, force_no_weights_only_load = False

    def load(
        f: FileLike,
        map_location: MAP_LOCATION = None,
        pickle_module: Any = None,
        *,
        weights_only: Optional[bool] = None,
        mmap: Optional[bool] = None,
        **pickle_load_args: Any,
    ) -> Any:
        # Reference: https://github.com/pytorch/pytorch/issues/54354
        # The first line of this docstring overrides the one Sphinx generates for the
        # documentation. We need it so that Sphinx doesn't leak `pickle`s path from
        # the build environment (e.g. `<module 'pickle' from '/leaked/path').
    
        """load(f, map_location=None, pickle_module=pickle, *, weights_only=True, mmap=None, **pickle_load_args)
    
        Loads an object saved with :func:`torch.save` from a file.
    
        :func:`torch.load` uses Python's unpickling facilities but treats storages,
        which underlie tensors, specially. They are first deserialized on the
        CPU and are then moved to the device they were saved from. If this fails
        (e.g. because the run time system doesn't have certain devices), an exception
        is raised. However, storages can be dynamically remapped to an alternative
        set of devices using the :attr:`map_location` argument.
    
        If :attr:`map_location` is a callable, it will be called once for each serialized
        storage with two arguments: storage and location. The storage argument
        will be the initial deserialization of the storage, residing on the CPU.
        Each serialized storage has a location tag associated with it which
        identifies the device it was saved from, and this tag is the second
        argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``
        for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.
        :attr:`map_location` should return either ``None`` or a storage. If
        :attr:`map_location` returns a storage, it will be used as the final deserialized
        object, already moved to the right device. Otherwise, :func:`torch.load` will
        fall back to the default behavior, as if :attr:`map_location` wasn't specified.
    
        If :attr:`map_location` is a :class:`torch.device` object or a string containing
        a device tag, it indicates the location where all tensors should be loaded.
    
        Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags
        appearing in the file (keys), to ones that specify where to put the
        storages (values).
    
        User extensions can register their own location tags and tagging and
        deserialization methods using :func:`torch.serialization.register_package`.
    
        See :ref:`layout-control` for more advanced tools to manipulate a checkpoint.
    
        Args:
            f: a file-like object (has to implement :meth:`read`, :meth:`readline`, :meth:`tell`, and :meth:`seek`),
                or a string or os.PathLike object containing a file name
            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage
                locations
            pickle_module: module used for unpickling metadata and objects (has to
                match the :attr:`pickle_module` used to serialize file)
            weights_only: Indicates whether unpickler should be restricted to
                loading only tensors, primitive types, dictionaries
                and any types added via :func:`torch.serialization.add_safe_globals`.
                See :ref:`weights-only` for more details.
            mmap: Indicates whether the file should be mmaped rather than loading all the storages into memory.
                Typically, tensor storages in the file will first be moved from disk to CPU memory, after which they
                are moved to the location that they were tagged with when saving, or specified by ``map_location``. This
                second step is a no-op if the final location is CPU. When the ``mmap`` flag is set, instead of copying the
                tensor storages from disk to CPU memory in the first step, ``f`` is mmaped, which means tensor storages
                will be lazily loaded when their data is accessed.
            pickle_load_args: (Python 3 only) optional keyword arguments passed over to
                :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,
                :attr:`errors=...`.
    
        .. warning::
            :func:`torch.load()` unless `weights_only` parameter is set to `True`,
            uses ``pickle`` module implicitly, which is known to be insecure.
            It is possible to construct malicious pickle data which will execute arbitrary code
            during unpickling. Never load data that could have come from an untrusted
            source in an unsafe mode, or that could have been tampered with. **Only load data you trust**.
    
        .. note::
            When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors
            will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``
            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.
    
        .. note::
            By default, we decode byte strings as ``utf-8``.  This is to avoid a common error
            case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``
            when loading files saved by Python 2 in Python 3.  If this default
            is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how
            these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them
            to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them
            as byte arrays which can be decoded later with ``byte_array.decode(...)``.
    
        Example:
            >>> # xdoctest: +SKIP("undefined filepaths")
            >>> torch.load("tensors.pt", weights_only=True)
            # Load all tensors onto the CPU
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=torch.device("cpu"),
            ...     weights_only=True,
            ... )
            # Load all tensors onto the CPU, using a function
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage,
            ...     weights_only=True,
            ... )
            # Load all tensors onto GPU 1
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage.cuda(1),
            ...     weights_only=True,
            ... )  # type: ignore[attr-defined]
            # Map tensors from GPU 1 to GPU 0
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location={"cuda:1": "cuda:0"},
            ...     weights_only=True,
            ... )
            # Load tensor from io.BytesIO object
            # Loading from a buffer setting weights_only=False, warning this can be unsafe
            >>> with open("tensor.pt", "rb") as f:
            ...     buffer = io.BytesIO(f.read())
            >>> torch.load(buffer, weights_only=False)
            # Load a module with 'ascii' encoding for unpickling
            # Loading from a module setting weights_only=False, warning this can be unsafe
            >>> torch.load("module.pt", encoding="ascii", weights_only=False)
        """
        torch._C._log_api_usage_once("torch.load")
        DOCS_MESSAGE = (
            "\n\nCheck the documentation of torch.load to learn more about types accepted by default with "
            "weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
        )
    
        def _get_wo_message(message: str) -> str:
            unsafe_global_pattern = r"GLOBAL (\S+) was not an allowed global by default."
            has_unsafe_global = re.search(unsafe_global_pattern, message) is not None
            blocklist_pattern = r"whose module (\S+) is blocked"
            has_blocklist = re.search(blocklist_pattern, message) is not None
            import_pattern = r"(\S+) must be (\S+) to load"
            has_import = re.search(import_pattern, message) is not None
            if has_unsafe_global:
                updated_message = (
                    "Weights only load failed. This file can still be loaded, to do so you have two options, "
                    "\033[1mdo those steps only if you trust the source of the checkpoint\033[0m. "
                    f"\n\t(1) {UNSAFE_MESSAGE}\n\t(2) Alternatively, to load with `weights_only=True` please check "
                    "the recommended steps in the following error message.\n\tWeightsUnpickler error: "
                    + message
                )
            else:
                if has_import:
                    return f"Weights only load failed. {message}\n {UNSAFE_MESSAGE}\n"
                else:
                    updated_message = f"Weights only load failed. {UNSAFE_MESSAGE}\n"
                    if not has_blocklist:
                        updated_message += (
                            "Please file an issue with the following so that we can make "
                            "`weights_only=True` compatible with your use case: WeightsUnpickler error: "
                        )
                updated_message += message
            return updated_message + DOCS_MESSAGE
    
        weights_only_not_set = weights_only is None
    
        if weights_only_not_set:
            weights_only = _default_to_weights_only(pickle_module)
    
        true_values = ["1", "y", "yes", "true"]
        # Add ability to force safe only or non-safe weight loads via environment variables
        force_weights_only_load = (
            os.getenv("TORCH_FORCE_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
        force_no_weights_only_load = (
            os.getenv("TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
    
        if force_weights_only_load and force_no_weights_only_load:
            raise RuntimeError(
                "Only one of `TORCH_FORCE_WEIGHTS_ONLY_LOAD` or `TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD` "
                "should be set, but both were set."
            )
        elif force_weights_only_load:
            weights_only = True
        elif force_no_weights_only_load:
            # TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD can only override if callsite did not explicitly set weights_only
            if weights_only_not_set:
                warnings.warn(
                    "Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the"
                    "`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.",
                    UserWarning,
                    stacklevel=2,
                )
                weights_only = False
    
        if weights_only:
            if pickle_module is not None:
                raise RuntimeError(
                    "Can not safely load weights when explicit pickle_module is specified"
                )
        else:
            if pickle_module is None:
                pickle_module = pickle
    
        # make flipping default BC-compatible
        if mmap is None:
            from torch.utils.serialization import config
    
            mmap = config.load.mmap
    
        _check_dill_version(pickle_module)
    
        if "encoding" not in pickle_load_args.keys():
            pickle_load_args["encoding"] = "utf-8"
    
        with _open_file_like(f, "rb") as opened_file:
            if _is_zipfile(opened_file):
                # The zipfile reader is going to advance the current file position.
                # If we want to actually tail call to torch.jit.load, we need to
                # reset back to the original position.
                orig_position = opened_file.tell()
                overall_storage = None
                with _open_zipfile_reader(opened_file) as opened_zipfile:
                    if _is_torchscript_zip(opened_zipfile):
                        warnings.warn(
                            "'torch.load' received a zip file that looks like a TorchScript archive"
                            " dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to"
                            " silence this warning)",
                            UserWarning,
                        )
                        if weights_only:
                            raise RuntimeError(
                                "Cannot use ``weights_only=True`` with TorchScript archives passed to "
                                "``torch.load``. " + UNSAFE_MESSAGE
                            )
                        opened_file.seek(orig_position)
                        return torch.jit.load(opened_file, map_location=map_location)
                    if mmap:
                        if not _is_path(f):
                            raise ValueError(
                                "f must be a file path in order to use the mmap argument"
                            )
                        size = os.path.getsize(f)
                        if not IS_WINDOWS:
                            shared = get_default_mmap_options() == MAP_SHARED
                        else:
                            shared = False
                        overall_storage = torch.UntypedStorage.from_file(
                            os.fspath(f), shared, size
                        )
                    if weights_only:
                        try:
                            return _load(
                                opened_zipfile,
                                map_location,
                                _weights_only_unpickler,
                                overall_storage=overall_storage,
                                **pickle_load_args,
                            )
                        except pickle.UnpicklingError as e:
>                           raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
E                           _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
E                           	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
E                           	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
E                           	WeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.
E                           
E                           Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\torch\serialization.py:1529: UnpicklingError
________________ TestObjectDetection.test_yolo_detect_on_frame ________________

self = <test_pipeline_video.TestObjectDetection object at 0x000001E0BF815810>
first_frame = array([[[ 90,  93,  83],
        [ 94,  97,  87],
        [101, 104,  94],
        ...,
        [ 44,  92,  71],
     ...  ...,
        [120, 106,  79],
        [120, 106,  79],
        [120, 106,  79]]], shape=(1080, 1920, 3), dtype=uint8)

    def test_yolo_detect_on_frame(self, first_frame):
        from object_detection import YOLODetector
>       detector = YOLODetector(model_path="yolov8n.pt", device="cpu")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:240: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_detection.YOLODetector object at 0x000001E0D5642490>
model_path = 'yolov8n.pt', conf_threshold = 0.25, iou_threshold = 0.45
device = 'cpu', classes = None

    def __init__(
        self,
        model_path: str = "yolov8s.pt",
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45,
        device: str = "0",
        classes: Optional[List[int]] = None,
    ):
        """
        Args:
            model_path: Path to YOLOv8 weights (.pt file)
            conf_threshold: Minimum confidence for detections
            iou_threshold: NMS IoU threshold
            device: CUDA device ("0") or "cpu"
            classes: List of class indices to detect (None = all)
        """
        try:
            from ultralytics import YOLO
>           self.model = YOLO(model_path)
                         ^^^^^^^^^^^^^^^^

src\object_detection.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), model = 'yolov8n.pt', task = None

    def __init__(self, model: Union[str, Path] = 'yolov8n.pt', task=None) -> None:
        """
        Initializes the YOLO model.
    
        Args:
            model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to 'yolov8n.pt'.
            task (Any, optional): Task type for the YOLO model. Defaults to None.
        """
        super().__init__()
        self.callbacks = callbacks.get_default_callbacks()
        self.predictor = None  # reuse predictor
        self.model = None  # model object
        self.trainer = None  # trainer object
        self.ckpt = None  # if loaded from *.pt
        self.cfg = None  # if loaded from *.yaml
        self.ckpt_path = None
        self.overrides = {}  # overrides for trainer object
        self.metrics = None  # validation/training metrics
        self.session = None  # HUB session
        self.task = task  # task type
        model = str(model).strip()  # strip spaces
    
        # Check if Ultralytics HUB model from https://hub.ultralytics.com
        if self.is_hub_model(model):
            from ultralytics.hub.session import HUBTrainingSession
            self.session = HUBTrainingSession(model)
            model = self.session.model_file
    
        # Check if Triton Server model
        elif self.is_triton_model(model):
            self.model = model
            self.task = task
            return
    
        # Load or create new YOLO model
        suffix = Path(model).suffix
        if not suffix and Path(model).stem in GITHUB_ASSETS_STEMS:
            model, suffix = Path(model).with_suffix('.pt'), '.pt'  # add suffix, i.e. yolov8n -> yolov8n.pt
        if suffix in ('.yaml', '.yml'):
            self._new(model, task)
        else:
>           self._load(model, task)

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), weights = 'yolov8n.pt', task = None

    def _load(self, weights: str, task=None):
        """
        Initializes a new model and infers the task type from the model head.
    
        Args:
            weights (str): model checkpoint to be loaded
            task (str | None): model task
        """
        suffix = Path(weights).suffix
        if suffix == '.pt':
>           self.model, self.ckpt = attempt_load_one_weight(weights)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt', device = None, inplace = True, fuse = False

    def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):
        """Loads a single model weights."""
>       ckpt, weight = torch_safe_load(weight)  # load ckpt
                       ^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:628: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt'

    def torch_safe_load(weight):
        """
        This function attempts to load a PyTorch model with the torch.load() function. If a ModuleNotFoundError is raised,
        it catches the error, logs a warning message, and attempts to install the missing module via the
        check_requirements() function. After installation, the function again attempts to load the model using torch.load().
    
        Args:
            weight (str): The file path of the PyTorch model.
    
        Returns:
            (dict): The loaded PyTorch model.
        """
        from ultralytics.utils.downloads import attempt_download_asset
    
        check_suffix(file=weight, suffix='.pt')
        file = attempt_download_asset(weight)  # search online if missing locally
        try:
            with temporary_modules({
                    'ultralytics.yolo.utils': 'ultralytics.utils',
                    'ultralytics.yolo.v8': 'ultralytics.models.yolo',
                    'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models
>               return torch.load(file, map_location='cpu'), file  # load
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:567: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

f = 'yolov8n.pt', map_location = 'cpu', pickle_module = None
weights_only = True, mmap = False, pickle_load_args = {'encoding': 'utf-8'}
_get_wo_message = <function load.<locals>._get_wo_message at 0x000001E0D56B2AC0>
weights_only_not_set = True, true_values = ['1', 'y', 'yes', 'true']
force_weights_only_load = False, force_no_weights_only_load = False

    def load(
        f: FileLike,
        map_location: MAP_LOCATION = None,
        pickle_module: Any = None,
        *,
        weights_only: Optional[bool] = None,
        mmap: Optional[bool] = None,
        **pickle_load_args: Any,
    ) -> Any:
        # Reference: https://github.com/pytorch/pytorch/issues/54354
        # The first line of this docstring overrides the one Sphinx generates for the
        # documentation. We need it so that Sphinx doesn't leak `pickle`s path from
        # the build environment (e.g. `<module 'pickle' from '/leaked/path').
    
        """load(f, map_location=None, pickle_module=pickle, *, weights_only=True, mmap=None, **pickle_load_args)
    
        Loads an object saved with :func:`torch.save` from a file.
    
        :func:`torch.load` uses Python's unpickling facilities but treats storages,
        which underlie tensors, specially. They are first deserialized on the
        CPU and are then moved to the device they were saved from. If this fails
        (e.g. because the run time system doesn't have certain devices), an exception
        is raised. However, storages can be dynamically remapped to an alternative
        set of devices using the :attr:`map_location` argument.
    
        If :attr:`map_location` is a callable, it will be called once for each serialized
        storage with two arguments: storage and location. The storage argument
        will be the initial deserialization of the storage, residing on the CPU.
        Each serialized storage has a location tag associated with it which
        identifies the device it was saved from, and this tag is the second
        argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``
        for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.
        :attr:`map_location` should return either ``None`` or a storage. If
        :attr:`map_location` returns a storage, it will be used as the final deserialized
        object, already moved to the right device. Otherwise, :func:`torch.load` will
        fall back to the default behavior, as if :attr:`map_location` wasn't specified.
    
        If :attr:`map_location` is a :class:`torch.device` object or a string containing
        a device tag, it indicates the location where all tensors should be loaded.
    
        Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags
        appearing in the file (keys), to ones that specify where to put the
        storages (values).
    
        User extensions can register their own location tags and tagging and
        deserialization methods using :func:`torch.serialization.register_package`.
    
        See :ref:`layout-control` for more advanced tools to manipulate a checkpoint.
    
        Args:
            f: a file-like object (has to implement :meth:`read`, :meth:`readline`, :meth:`tell`, and :meth:`seek`),
                or a string or os.PathLike object containing a file name
            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage
                locations
            pickle_module: module used for unpickling metadata and objects (has to
                match the :attr:`pickle_module` used to serialize file)
            weights_only: Indicates whether unpickler should be restricted to
                loading only tensors, primitive types, dictionaries
                and any types added via :func:`torch.serialization.add_safe_globals`.
                See :ref:`weights-only` for more details.
            mmap: Indicates whether the file should be mmaped rather than loading all the storages into memory.
                Typically, tensor storages in the file will first be moved from disk to CPU memory, after which they
                are moved to the location that they were tagged with when saving, or specified by ``map_location``. This
                second step is a no-op if the final location is CPU. When the ``mmap`` flag is set, instead of copying the
                tensor storages from disk to CPU memory in the first step, ``f`` is mmaped, which means tensor storages
                will be lazily loaded when their data is accessed.
            pickle_load_args: (Python 3 only) optional keyword arguments passed over to
                :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,
                :attr:`errors=...`.
    
        .. warning::
            :func:`torch.load()` unless `weights_only` parameter is set to `True`,
            uses ``pickle`` module implicitly, which is known to be insecure.
            It is possible to construct malicious pickle data which will execute arbitrary code
            during unpickling. Never load data that could have come from an untrusted
            source in an unsafe mode, or that could have been tampered with. **Only load data you trust**.
    
        .. note::
            When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors
            will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``
            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.
    
        .. note::
            By default, we decode byte strings as ``utf-8``.  This is to avoid a common error
            case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``
            when loading files saved by Python 2 in Python 3.  If this default
            is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how
            these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them
            to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them
            as byte arrays which can be decoded later with ``byte_array.decode(...)``.
    
        Example:
            >>> # xdoctest: +SKIP("undefined filepaths")
            >>> torch.load("tensors.pt", weights_only=True)
            # Load all tensors onto the CPU
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=torch.device("cpu"),
            ...     weights_only=True,
            ... )
            # Load all tensors onto the CPU, using a function
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage,
            ...     weights_only=True,
            ... )
            # Load all tensors onto GPU 1
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage.cuda(1),
            ...     weights_only=True,
            ... )  # type: ignore[attr-defined]
            # Map tensors from GPU 1 to GPU 0
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location={"cuda:1": "cuda:0"},
            ...     weights_only=True,
            ... )
            # Load tensor from io.BytesIO object
            # Loading from a buffer setting weights_only=False, warning this can be unsafe
            >>> with open("tensor.pt", "rb") as f:
            ...     buffer = io.BytesIO(f.read())
            >>> torch.load(buffer, weights_only=False)
            # Load a module with 'ascii' encoding for unpickling
            # Loading from a module setting weights_only=False, warning this can be unsafe
            >>> torch.load("module.pt", encoding="ascii", weights_only=False)
        """
        torch._C._log_api_usage_once("torch.load")
        DOCS_MESSAGE = (
            "\n\nCheck the documentation of torch.load to learn more about types accepted by default with "
            "weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
        )
    
        def _get_wo_message(message: str) -> str:
            unsafe_global_pattern = r"GLOBAL (\S+) was not an allowed global by default."
            has_unsafe_global = re.search(unsafe_global_pattern, message) is not None
            blocklist_pattern = r"whose module (\S+) is blocked"
            has_blocklist = re.search(blocklist_pattern, message) is not None
            import_pattern = r"(\S+) must be (\S+) to load"
            has_import = re.search(import_pattern, message) is not None
            if has_unsafe_global:
                updated_message = (
                    "Weights only load failed. This file can still be loaded, to do so you have two options, "
                    "\033[1mdo those steps only if you trust the source of the checkpoint\033[0m. "
                    f"\n\t(1) {UNSAFE_MESSAGE}\n\t(2) Alternatively, to load with `weights_only=True` please check "
                    "the recommended steps in the following error message.\n\tWeightsUnpickler error: "
                    + message
                )
            else:
                if has_import:
                    return f"Weights only load failed. {message}\n {UNSAFE_MESSAGE}\n"
                else:
                    updated_message = f"Weights only load failed. {UNSAFE_MESSAGE}\n"
                    if not has_blocklist:
                        updated_message += (
                            "Please file an issue with the following so that we can make "
                            "`weights_only=True` compatible with your use case: WeightsUnpickler error: "
                        )
                updated_message += message
            return updated_message + DOCS_MESSAGE
    
        weights_only_not_set = weights_only is None
    
        if weights_only_not_set:
            weights_only = _default_to_weights_only(pickle_module)
    
        true_values = ["1", "y", "yes", "true"]
        # Add ability to force safe only or non-safe weight loads via environment variables
        force_weights_only_load = (
            os.getenv("TORCH_FORCE_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
        force_no_weights_only_load = (
            os.getenv("TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
    
        if force_weights_only_load and force_no_weights_only_load:
            raise RuntimeError(
                "Only one of `TORCH_FORCE_WEIGHTS_ONLY_LOAD` or `TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD` "
                "should be set, but both were set."
            )
        elif force_weights_only_load:
            weights_only = True
        elif force_no_weights_only_load:
            # TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD can only override if callsite did not explicitly set weights_only
            if weights_only_not_set:
                warnings.warn(
                    "Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the"
                    "`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.",
                    UserWarning,
                    stacklevel=2,
                )
                weights_only = False
    
        if weights_only:
            if pickle_module is not None:
                raise RuntimeError(
                    "Can not safely load weights when explicit pickle_module is specified"
                )
        else:
            if pickle_module is None:
                pickle_module = pickle
    
        # make flipping default BC-compatible
        if mmap is None:
            from torch.utils.serialization import config
    
            mmap = config.load.mmap
    
        _check_dill_version(pickle_module)
    
        if "encoding" not in pickle_load_args.keys():
            pickle_load_args["encoding"] = "utf-8"
    
        with _open_file_like(f, "rb") as opened_file:
            if _is_zipfile(opened_file):
                # The zipfile reader is going to advance the current file position.
                # If we want to actually tail call to torch.jit.load, we need to
                # reset back to the original position.
                orig_position = opened_file.tell()
                overall_storage = None
                with _open_zipfile_reader(opened_file) as opened_zipfile:
                    if _is_torchscript_zip(opened_zipfile):
                        warnings.warn(
                            "'torch.load' received a zip file that looks like a TorchScript archive"
                            " dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to"
                            " silence this warning)",
                            UserWarning,
                        )
                        if weights_only:
                            raise RuntimeError(
                                "Cannot use ``weights_only=True`` with TorchScript archives passed to "
                                "``torch.load``. " + UNSAFE_MESSAGE
                            )
                        opened_file.seek(orig_position)
                        return torch.jit.load(opened_file, map_location=map_location)
                    if mmap:
                        if not _is_path(f):
                            raise ValueError(
                                "f must be a file path in order to use the mmap argument"
                            )
                        size = os.path.getsize(f)
                        if not IS_WINDOWS:
                            shared = get_default_mmap_options() == MAP_SHARED
                        else:
                            shared = False
                        overall_storage = torch.UntypedStorage.from_file(
                            os.fspath(f), shared, size
                        )
                    if weights_only:
                        try:
                            return _load(
                                opened_zipfile,
                                map_location,
                                _weights_only_unpickler,
                                overall_storage=overall_storage,
                                **pickle_load_args,
                            )
                        except pickle.UnpicklingError as e:
>                           raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
E                           _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
E                           	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
E                           	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
E                           	WeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.
E                           
E                           Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\torch\serialization.py:1529: UnpicklingError
_____________ TestObjectDetection.test_classical_player_detector ______________

self = <test_pipeline_video.TestObjectDetection object at 0x000001E0BF404D10>
first_frame = array([[[ 90,  93,  83],
        [ 94,  97,  87],
        [101, 104,  94],
        ...,
        [ 44,  92,  71],
     ...  ...,
        [120, 106,  79],
        [120, 106,  79],
        [120, 106,  79]]], shape=(1080, 1920, 3), dtype=uint8)

    def test_classical_player_detector(self, first_frame):
        from object_detection import ClassicalPlayerDetector
        detector = ClassicalPlayerDetector(method="hog")
>       detections = detector.detect(first_frame)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_detection.ClassicalPlayerDetector object at 0x000001E0D568D6A0>
frame = array([[[ 90,  93,  83],
        [ 94,  97,  87],
        [101, 104,  94],
        ...,
        [ 44,  92,  71],
     ...  ...,
        [120, 106,  79],
        [120, 106,  79],
        [120, 106,  79]]], shape=(1080, 1920, 3), dtype=uint8)
confidence_threshold = 0.3

    def detect(
        self, frame: np.ndarray, confidence_threshold: float = 0.3
    ) -> List[Detection]:
        """
        Detect players in frame using classical methods.
    
        Returns list of Detection objects for players found.
        """
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        detections = []
    
        if self.method == "haar":
            rects = self.cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=3,
                minSize=(40, 80),
                flags=cv2.CASCADE_SCALE_IMAGE,
            )
            for (x, y, w, h) in rects:
                det = Detection(
                    bbox=(x, y, x + w, y + h),
                    confidence=0.5,  # Haar doesn't give confidence
                    class_id=1,
                    class_name="player",
                )
                detections.append(det)
    
        elif self.method == "hog":
            rects, weights = self.hog.detectMultiScale(
                gray,
                winStride=(8, 8),
                padding=(4, 4),
                scale=1.05,
            )
            for (x, y, w, h), weight in zip(rects, weights):
>               conf = float(weight[0]) if len(weight) > 0 else 0.5
                                           ^^^^^^^^^^^
E               TypeError: object of type 'numpy.float64' has no len()

src\object_detection.py:195: TypeError
_______________________ TestObjectTracking.test_import ________________________

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF37E350>

    def test_import(self):
>       from object_tracking import (
            BallKalmanTracker, OpticalFlowEstimator,
            MultiObjectTracker, TrackState, PlayerTrack,
        )
E       ImportError: cannot import name 'MultiObjectTracker' from 'object_tracking' (D:\Downloads\cv\tennis-pickleball-tracker\src\object_tracking.py)

tests\test_pipeline_video.py:282: ImportError
_________________ TestObjectTracking.test_kalman_filter_init __________________

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF37EAD0>

    def test_kalman_filter_init(self):
        from object_tracking import BallKalmanTracker
        tracker = BallKalmanTracker(dt=1.0 / 30.0)
>       assert not tracker.initialized
                   ^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'BallKalmanTracker' object has no attribute 'initialized'

tests\test_pipeline_video.py:290: AttributeError
________ TestObjectTracking.test_kalman_filter_update_with_measurement ________

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF814FC0>

    def test_kalman_filter_update_with_measurement(self):
        from object_tracking import BallKalmanTracker
        tracker = BallKalmanTracker(dt=1.0 / 30.0)
    
        # First measurement initializes the tracker
        m1 = np.array([100.0, 200.0])
>       state = tracker.update(m1)
                ^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_tracking.BallKalmanTracker object at 0x000001E0D5643D90>
detection = array([        100,         200])

    def update(self, detection: Optional[Detection]) -> Tuple[float, float]:
        """
        Kalman UPDATE step: correct prediction with new measurement.
    
        If detection is None, only prediction is used (no correction).
    
        Args:
            detection: Ball detection for current frame, or None
    
        Returns:
            Estimated (x, y) position after update
        """
        self.frame_count += 1
    
        if detection is not None:
>           cx, cy = detection.center
                     ^^^^^^^^^^^^^^^^
E           AttributeError: 'numpy.ndarray' object has no attribute 'center'

src\object_tracking.py:196: AttributeError
______ TestObjectTracking.test_kalman_filter_update_without_measurement _______

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF815940>

    def test_kalman_filter_update_without_measurement(self):
        from object_tracking import BallKalmanTracker
>       tracker = BallKalmanTracker(dt=1.0 / 30.0, max_misses=5)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: BallKalmanTracker.__init__() got an unexpected keyword argument 'max_misses'

tests\test_pipeline_video.py:312: TypeError
______________ TestObjectTracking.test_kalman_filter_trajectory _______________

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF83CA70>

    def test_kalman_filter_trajectory(self):
        from object_tracking import BallKalmanTracker
        tracker = BallKalmanTracker(dt=1.0 / 30.0)
    
        # Simulate a simple trajectory
        for i in range(20):
>           tracker.update(np.array([100.0 + i * 5, 200.0 + i * 3]))

tests\test_pipeline_video.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_tracking.BallKalmanTracker object at 0x000001E0D5643D90>
detection = array([        100,         200])

    def update(self, detection: Optional[Detection]) -> Tuple[float, float]:
        """
        Kalman UPDATE step: correct prediction with new measurement.
    
        If detection is None, only prediction is used (no correction).
    
        Args:
            detection: Ball detection for current frame, or None
    
        Returns:
            Estimated (x, y) position after update
        """
        self.frame_count += 1
    
        if detection is not None:
>           cx, cy = detection.center
                     ^^^^^^^^^^^^^^^^
E           AttributeError: 'numpy.ndarray' object has no attribute 'center'

src\object_tracking.py:196: AttributeError
_______________ TestObjectTracking.test_optical_flow_estimator ________________

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF404F30>
sample_frames = [(189, array([[[ 90,  97,  83],
        [ 93, 100,  86],
        [100, 107,  93],
        ...,
        [ 48,  93,  73]......,
        [171, 143, 130],
        [157, 123, 113],
        [141, 107,  97]]], shape=(1080, 1920, 3), dtype=uint8))]

    def test_optical_flow_estimator(self, sample_frames):
        from object_tracking import OpticalFlowEstimator
        estimator = OpticalFlowEstimator()
    
        idx0, frame0 = sample_frames[0]
        idx1, frame1 = sample_frames[1]
    
        # First call ù no previous frame
>       vel = estimator.estimate_velocity(frame0, (320, 240))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'OpticalFlowEstimator' object has no attribute 'estimate_velocity'. Did you mean: 'estimate_ball_velocity'?

tests\test_pipeline_video.py:349: AttributeError
__________ TestObjectTracking.test_multi_object_tracker_no_deepsort ___________

self = <test_pipeline_video.TestObjectTracking object at 0x000001E0BF405040>
video_info = {'fps': 30.0, 'height': 1080, 'total_frames': 1139, 'width': 1920}

    def test_multi_object_tracker_no_deepsort(self, video_info):
>       from object_tracking import MultiObjectTracker
E       ImportError: cannot import name 'MultiObjectTracker' from 'object_tracking' (D:\Downloads\cv\tennis-pickleball-tracker\src\object_tracking.py)

tests\test_pipeline_video.py:358: ImportError
__________________ TestVisualization.test_heatmap_generator ___________________

self = <test_pipeline_video.TestVisualization object at 0x000001E0BF405590>

    def test_heatmap_generator(self):
        from visualization import HeatmapGenerator
        hg = HeatmapGenerator()
        # Add some positions
        for _ in range(50):
            hg.add_ball_position(
                np.random.uniform(0, 23.77),
                np.random.uniform(0, 10.97),
            )
>       img = hg.get_ball_heatmap_image()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:544: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <visualization.HeatmapGenerator object at 0x000001E08E206270>
save_path = None

    def get_ball_heatmap_image(
        self, save_path: Optional[str] = None
    ) -> np.ndarray:
        """Render ball position heatmap."""
>       return self.render_heatmap(
            self.ball_heatmap,
            title="Ball Position Heatmap",
            save_path=save_path,
        )

src\visualization.py:541: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <visualization.HeatmapGenerator object at 0x000001E08E206270>
heatmap = array([[          0,           0,           0, ...,           0,           0,           0],
       [          0,      ...     0],
       [          0,           0,           0, ...,           0,           0,           0]], shape=(237, 109))
title = 'Ball Position Heatmap', save_path = None

    def render_heatmap(
        self,
        heatmap: np.ndarray,
        title: str = "Heatmap",
        save_path: Optional[str] = None,
    ) -> np.ndarray:
        """
        Render a heatmap as a matplotlib figure.
    
        Returns the figure as a BGR image array.
        """
        fig, ax = plt.subplots(1, 1, figsize=(6, 12))
    
        # Apply Gaussian smoothing
        from scipy.ndimage import gaussian_filter
        smoothed = gaussian_filter(heatmap.T, sigma=2)
    
        ax.imshow(
            smoothed,
            cmap="hot",
            interpolation="bilinear",
            origin="lower",
            extent=[0, self.court_length, 0, self.court_width],
            aspect="auto",
        )
    
        # Draw court lines overlay
        ax.axhline(y=1.37, color="white", linewidth=0.5, alpha=0.5)
        ax.axhline(y=9.60, color="white", linewidth=0.5, alpha=0.5)
        ax.axvline(x=6.40, color="white", linewidth=0.5, alpha=0.5)
        ax.axvline(x=17.37, color="white", linewidth=0.5, alpha=0.5)
        ax.axvline(x=11.885, color="white", linewidth=1.0, alpha=0.7)
    
        ax.set_title(title)
        ax.set_xlabel("Court Length (m)")
        ax.set_ylabel("Court Width (m)")
    
        if save_path:
            fig.savefig(save_path, dpi=100, bbox_inches="tight")
    
        # Convert figure to image array
        fig.canvas.draw()
>       img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
                            ^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'FigureCanvasAgg' object has no attribute 'tostring_rgb'. Did you mean: 'tostring_argb'?

src\visualization.py:530: AttributeError
__________________ TestEndToEndPipeline.test_pipeline_import __________________

self = <test_pipeline_video.TestEndToEndPipeline object at 0x000001E0BF37EE90>

    def test_pipeline_import(self):
>       from pipeline import run, parse_args
E       ImportError: cannot import name 'run' from 'pipeline' (D:\Downloads\cv\tennis-pickleball-tracker\src\pipeline.py)

tests\test_pipeline_video.py:574: ImportError
________________ TestEndToEndPipeline.test_pipeline_short_run _________________

self = <test_pipeline_video.TestEndToEndPipeline object at 0x000001E0BF37F4D0>
video_info = {'fps': 30.0, 'height': 1080, 'total_frames': 1139, 'width': 1920}

    def test_pipeline_short_run(self, video_info):
        """Run the full pipeline on the first 30 frames."""
>       from pipeline import run
E       ImportError: cannot import name 'run' from 'pipeline' (D:\Downloads\cv\tennis-pickleball-tracker\src\pipeline.py)

tests\test_pipeline_video.py:578: ImportError
________________ TestEndToEndPipeline.test_pipeline_100_frames ________________

self = <test_pipeline_video.TestEndToEndPipeline object at 0x000001E0BF816060>
video_info = {'fps': 30.0, 'height': 1080, 'total_frames': 1139, 'width': 1920}

    def test_pipeline_100_frames(self, video_info):
        """Run pipeline on 100 frames for a more thorough test."""
>       from pipeline import run
E       ImportError: cannot import name 'run' from 'pipeline' (D:\Downloads\cv\tennis-pickleball-tracker\src\pipeline.py)

tests\test_pipeline_video.py:629: ImportError
_________________ TestIntegration.test_detection_to_tracking __________________

self = <test_pipeline_video.TestIntegration object at 0x000001E0BF37F750>
first_frame = array([[[ 90,  93,  83],
        [ 94,  97,  87],
        [101, 104,  94],
        ...,
        [ 44,  92,  71],
     ...  ...,
        [120, 106,  79],
        [120, 106,  79],
        [120, 106,  79]]], shape=(1080, 1920, 3), dtype=uint8)

    def test_detection_to_tracking(self, first_frame):
        """Object detection -> Kalman tracking."""
        from object_detection import YOLODetector
        from object_tracking import BallKalmanTracker
    
>       detector = YOLODetector(model_path="yolov8n.pt", device="cpu")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_detection.YOLODetector object at 0x000001E08E333110>
model_path = 'yolov8n.pt', conf_threshold = 0.25, iou_threshold = 0.45
device = 'cpu', classes = None

    def __init__(
        self,
        model_path: str = "yolov8s.pt",
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45,
        device: str = "0",
        classes: Optional[List[int]] = None,
    ):
        """
        Args:
            model_path: Path to YOLOv8 weights (.pt file)
            conf_threshold: Minimum confidence for detections
            iou_threshold: NMS IoU threshold
            device: CUDA device ("0") or "cpu"
            classes: List of class indices to detect (None = all)
        """
        try:
            from ultralytics import YOLO
>           self.model = YOLO(model_path)
                         ^^^^^^^^^^^^^^^^

src\object_detection.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), model = 'yolov8n.pt', task = None

    def __init__(self, model: Union[str, Path] = 'yolov8n.pt', task=None) -> None:
        """
        Initializes the YOLO model.
    
        Args:
            model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to 'yolov8n.pt'.
            task (Any, optional): Task type for the YOLO model. Defaults to None.
        """
        super().__init__()
        self.callbacks = callbacks.get_default_callbacks()
        self.predictor = None  # reuse predictor
        self.model = None  # model object
        self.trainer = None  # trainer object
        self.ckpt = None  # if loaded from *.pt
        self.cfg = None  # if loaded from *.yaml
        self.ckpt_path = None
        self.overrides = {}  # overrides for trainer object
        self.metrics = None  # validation/training metrics
        self.session = None  # HUB session
        self.task = task  # task type
        model = str(model).strip()  # strip spaces
    
        # Check if Ultralytics HUB model from https://hub.ultralytics.com
        if self.is_hub_model(model):
            from ultralytics.hub.session import HUBTrainingSession
            self.session = HUBTrainingSession(model)
            model = self.session.model_file
    
        # Check if Triton Server model
        elif self.is_triton_model(model):
            self.model = model
            self.task = task
            return
    
        # Load or create new YOLO model
        suffix = Path(model).suffix
        if not suffix and Path(model).stem in GITHUB_ASSETS_STEMS:
            model, suffix = Path(model).with_suffix('.pt'), '.pt'  # add suffix, i.e. yolov8n -> yolov8n.pt
        if suffix in ('.yaml', '.yml'):
            self._new(model, task)
        else:
>           self._load(model, task)

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), weights = 'yolov8n.pt', task = None

    def _load(self, weights: str, task=None):
        """
        Initializes a new model and infers the task type from the model head.
    
        Args:
            weights (str): model checkpoint to be loaded
            task (str | None): model task
        """
        suffix = Path(weights).suffix
        if suffix == '.pt':
>           self.model, self.ckpt = attempt_load_one_weight(weights)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt', device = None, inplace = True, fuse = False

    def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):
        """Loads a single model weights."""
>       ckpt, weight = torch_safe_load(weight)  # load ckpt
                       ^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:628: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt'

    def torch_safe_load(weight):
        """
        This function attempts to load a PyTorch model with the torch.load() function. If a ModuleNotFoundError is raised,
        it catches the error, logs a warning message, and attempts to install the missing module via the
        check_requirements() function. After installation, the function again attempts to load the model using torch.load().
    
        Args:
            weight (str): The file path of the PyTorch model.
    
        Returns:
            (dict): The loaded PyTorch model.
        """
        from ultralytics.utils.downloads import attempt_download_asset
    
        check_suffix(file=weight, suffix='.pt')
        file = attempt_download_asset(weight)  # search online if missing locally
        try:
            with temporary_modules({
                    'ultralytics.yolo.utils': 'ultralytics.utils',
                    'ultralytics.yolo.v8': 'ultralytics.models.yolo',
                    'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models
>               return torch.load(file, map_location='cpu'), file  # load
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:567: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

f = 'yolov8n.pt', map_location = 'cpu', pickle_module = None
weights_only = True, mmap = False, pickle_load_args = {'encoding': 'utf-8'}
_get_wo_message = <function load.<locals>._get_wo_message at 0x000001E08E785F80>
weights_only_not_set = True, true_values = ['1', 'y', 'yes', 'true']
force_weights_only_load = False, force_no_weights_only_load = False

    def load(
        f: FileLike,
        map_location: MAP_LOCATION = None,
        pickle_module: Any = None,
        *,
        weights_only: Optional[bool] = None,
        mmap: Optional[bool] = None,
        **pickle_load_args: Any,
    ) -> Any:
        # Reference: https://github.com/pytorch/pytorch/issues/54354
        # The first line of this docstring overrides the one Sphinx generates for the
        # documentation. We need it so that Sphinx doesn't leak `pickle`s path from
        # the build environment (e.g. `<module 'pickle' from '/leaked/path').
    
        """load(f, map_location=None, pickle_module=pickle, *, weights_only=True, mmap=None, **pickle_load_args)
    
        Loads an object saved with :func:`torch.save` from a file.
    
        :func:`torch.load` uses Python's unpickling facilities but treats storages,
        which underlie tensors, specially. They are first deserialized on the
        CPU and are then moved to the device they were saved from. If this fails
        (e.g. because the run time system doesn't have certain devices), an exception
        is raised. However, storages can be dynamically remapped to an alternative
        set of devices using the :attr:`map_location` argument.
    
        If :attr:`map_location` is a callable, it will be called once for each serialized
        storage with two arguments: storage and location. The storage argument
        will be the initial deserialization of the storage, residing on the CPU.
        Each serialized storage has a location tag associated with it which
        identifies the device it was saved from, and this tag is the second
        argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``
        for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.
        :attr:`map_location` should return either ``None`` or a storage. If
        :attr:`map_location` returns a storage, it will be used as the final deserialized
        object, already moved to the right device. Otherwise, :func:`torch.load` will
        fall back to the default behavior, as if :attr:`map_location` wasn't specified.
    
        If :attr:`map_location` is a :class:`torch.device` object or a string containing
        a device tag, it indicates the location where all tensors should be loaded.
    
        Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags
        appearing in the file (keys), to ones that specify where to put the
        storages (values).
    
        User extensions can register their own location tags and tagging and
        deserialization methods using :func:`torch.serialization.register_package`.
    
        See :ref:`layout-control` for more advanced tools to manipulate a checkpoint.
    
        Args:
            f: a file-like object (has to implement :meth:`read`, :meth:`readline`, :meth:`tell`, and :meth:`seek`),
                or a string or os.PathLike object containing a file name
            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage
                locations
            pickle_module: module used for unpickling metadata and objects (has to
                match the :attr:`pickle_module` used to serialize file)
            weights_only: Indicates whether unpickler should be restricted to
                loading only tensors, primitive types, dictionaries
                and any types added via :func:`torch.serialization.add_safe_globals`.
                See :ref:`weights-only` for more details.
            mmap: Indicates whether the file should be mmaped rather than loading all the storages into memory.
                Typically, tensor storages in the file will first be moved from disk to CPU memory, after which they
                are moved to the location that they were tagged with when saving, or specified by ``map_location``. This
                second step is a no-op if the final location is CPU. When the ``mmap`` flag is set, instead of copying the
                tensor storages from disk to CPU memory in the first step, ``f`` is mmaped, which means tensor storages
                will be lazily loaded when their data is accessed.
            pickle_load_args: (Python 3 only) optional keyword arguments passed over to
                :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,
                :attr:`errors=...`.
    
        .. warning::
            :func:`torch.load()` unless `weights_only` parameter is set to `True`,
            uses ``pickle`` module implicitly, which is known to be insecure.
            It is possible to construct malicious pickle data which will execute arbitrary code
            during unpickling. Never load data that could have come from an untrusted
            source in an unsafe mode, or that could have been tampered with. **Only load data you trust**.
    
        .. note::
            When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors
            will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``
            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.
    
        .. note::
            By default, we decode byte strings as ``utf-8``.  This is to avoid a common error
            case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``
            when loading files saved by Python 2 in Python 3.  If this default
            is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how
            these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them
            to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them
            as byte arrays which can be decoded later with ``byte_array.decode(...)``.
    
        Example:
            >>> # xdoctest: +SKIP("undefined filepaths")
            >>> torch.load("tensors.pt", weights_only=True)
            # Load all tensors onto the CPU
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=torch.device("cpu"),
            ...     weights_only=True,
            ... )
            # Load all tensors onto the CPU, using a function
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage,
            ...     weights_only=True,
            ... )
            # Load all tensors onto GPU 1
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage.cuda(1),
            ...     weights_only=True,
            ... )  # type: ignore[attr-defined]
            # Map tensors from GPU 1 to GPU 0
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location={"cuda:1": "cuda:0"},
            ...     weights_only=True,
            ... )
            # Load tensor from io.BytesIO object
            # Loading from a buffer setting weights_only=False, warning this can be unsafe
            >>> with open("tensor.pt", "rb") as f:
            ...     buffer = io.BytesIO(f.read())
            >>> torch.load(buffer, weights_only=False)
            # Load a module with 'ascii' encoding for unpickling
            # Loading from a module setting weights_only=False, warning this can be unsafe
            >>> torch.load("module.pt", encoding="ascii", weights_only=False)
        """
        torch._C._log_api_usage_once("torch.load")
        DOCS_MESSAGE = (
            "\n\nCheck the documentation of torch.load to learn more about types accepted by default with "
            "weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
        )
    
        def _get_wo_message(message: str) -> str:
            unsafe_global_pattern = r"GLOBAL (\S+) was not an allowed global by default."
            has_unsafe_global = re.search(unsafe_global_pattern, message) is not None
            blocklist_pattern = r"whose module (\S+) is blocked"
            has_blocklist = re.search(blocklist_pattern, message) is not None
            import_pattern = r"(\S+) must be (\S+) to load"
            has_import = re.search(import_pattern, message) is not None
            if has_unsafe_global:
                updated_message = (
                    "Weights only load failed. This file can still be loaded, to do so you have two options, "
                    "\033[1mdo those steps only if you trust the source of the checkpoint\033[0m. "
                    f"\n\t(1) {UNSAFE_MESSAGE}\n\t(2) Alternatively, to load with `weights_only=True` please check "
                    "the recommended steps in the following error message.\n\tWeightsUnpickler error: "
                    + message
                )
            else:
                if has_import:
                    return f"Weights only load failed. {message}\n {UNSAFE_MESSAGE}\n"
                else:
                    updated_message = f"Weights only load failed. {UNSAFE_MESSAGE}\n"
                    if not has_blocklist:
                        updated_message += (
                            "Please file an issue with the following so that we can make "
                            "`weights_only=True` compatible with your use case: WeightsUnpickler error: "
                        )
                updated_message += message
            return updated_message + DOCS_MESSAGE
    
        weights_only_not_set = weights_only is None
    
        if weights_only_not_set:
            weights_only = _default_to_weights_only(pickle_module)
    
        true_values = ["1", "y", "yes", "true"]
        # Add ability to force safe only or non-safe weight loads via environment variables
        force_weights_only_load = (
            os.getenv("TORCH_FORCE_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
        force_no_weights_only_load = (
            os.getenv("TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
    
        if force_weights_only_load and force_no_weights_only_load:
            raise RuntimeError(
                "Only one of `TORCH_FORCE_WEIGHTS_ONLY_LOAD` or `TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD` "
                "should be set, but both were set."
            )
        elif force_weights_only_load:
            weights_only = True
        elif force_no_weights_only_load:
            # TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD can only override if callsite did not explicitly set weights_only
            if weights_only_not_set:
                warnings.warn(
                    "Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the"
                    "`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.",
                    UserWarning,
                    stacklevel=2,
                )
                weights_only = False
    
        if weights_only:
            if pickle_module is not None:
                raise RuntimeError(
                    "Can not safely load weights when explicit pickle_module is specified"
                )
        else:
            if pickle_module is None:
                pickle_module = pickle
    
        # make flipping default BC-compatible
        if mmap is None:
            from torch.utils.serialization import config
    
            mmap = config.load.mmap
    
        _check_dill_version(pickle_module)
    
        if "encoding" not in pickle_load_args.keys():
            pickle_load_args["encoding"] = "utf-8"
    
        with _open_file_like(f, "rb") as opened_file:
            if _is_zipfile(opened_file):
                # The zipfile reader is going to advance the current file position.
                # If we want to actually tail call to torch.jit.load, we need to
                # reset back to the original position.
                orig_position = opened_file.tell()
                overall_storage = None
                with _open_zipfile_reader(opened_file) as opened_zipfile:
                    if _is_torchscript_zip(opened_zipfile):
                        warnings.warn(
                            "'torch.load' received a zip file that looks like a TorchScript archive"
                            " dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to"
                            " silence this warning)",
                            UserWarning,
                        )
                        if weights_only:
                            raise RuntimeError(
                                "Cannot use ``weights_only=True`` with TorchScript archives passed to "
                                "``torch.load``. " + UNSAFE_MESSAGE
                            )
                        opened_file.seek(orig_position)
                        return torch.jit.load(opened_file, map_location=map_location)
                    if mmap:
                        if not _is_path(f):
                            raise ValueError(
                                "f must be a file path in order to use the mmap argument"
                            )
                        size = os.path.getsize(f)
                        if not IS_WINDOWS:
                            shared = get_default_mmap_options() == MAP_SHARED
                        else:
                            shared = False
                        overall_storage = torch.UntypedStorage.from_file(
                            os.fspath(f), shared, size
                        )
                    if weights_only:
                        try:
                            return _load(
                                opened_zipfile,
                                map_location,
                                _weights_only_unpickler,
                                overall_storage=overall_storage,
                                **pickle_load_args,
                            )
                        except pickle.UnpicklingError as e:
>                           raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
E                           _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
E                           	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
E                           	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
E                           	WeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.
E                           
E                           Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\torch\serialization.py:1529: UnpicklingError
___________ TestIntegration.test_visualization_with_real_detections ___________

self = <test_pipeline_video.TestIntegration object at 0x000001E0BF816190>
first_frame = array([[[ 90,  93,  83],
        [ 94,  97,  87],
        [101, 104,  94],
        ...,
        [ 44,  92,  71],
     ...  ...,
        [120, 106,  79],
        [120, 106,  79],
        [120, 106,  79]]], shape=(1080, 1920, 3), dtype=uint8)

    def test_visualization_with_real_detections(self, first_frame):
        """Detection -> visualization overlay."""
        from object_detection import YOLODetector
        from visualization import FrameAnnotator
    
>       detector = YOLODetector(model_path="yolov8n.pt", device="cpu")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_pipeline_video.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <object_detection.YOLODetector object at 0x000001E08E2C5A70>
model_path = 'yolov8n.pt', conf_threshold = 0.25, iou_threshold = 0.45
device = 'cpu', classes = None

    def __init__(
        self,
        model_path: str = "yolov8s.pt",
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45,
        device: str = "0",
        classes: Optional[List[int]] = None,
    ):
        """
        Args:
            model_path: Path to YOLOv8 weights (.pt file)
            conf_threshold: Minimum confidence for detections
            iou_threshold: NMS IoU threshold
            device: CUDA device ("0") or "cpu"
            classes: List of class indices to detect (None = all)
        """
        try:
            from ultralytics import YOLO
>           self.model = YOLO(model_path)
                         ^^^^^^^^^^^^^^^^

src\object_detection.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), model = 'yolov8n.pt', task = None

    def __init__(self, model: Union[str, Path] = 'yolov8n.pt', task=None) -> None:
        """
        Initializes the YOLO model.
    
        Args:
            model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to 'yolov8n.pt'.
            task (Any, optional): Task type for the YOLO model. Defaults to None.
        """
        super().__init__()
        self.callbacks = callbacks.get_default_callbacks()
        self.predictor = None  # reuse predictor
        self.model = None  # model object
        self.trainer = None  # trainer object
        self.ckpt = None  # if loaded from *.pt
        self.cfg = None  # if loaded from *.yaml
        self.ckpt_path = None
        self.overrides = {}  # overrides for trainer object
        self.metrics = None  # validation/training metrics
        self.session = None  # HUB session
        self.task = task  # task type
        model = str(model).strip()  # strip spaces
    
        # Check if Ultralytics HUB model from https://hub.ultralytics.com
        if self.is_hub_model(model):
            from ultralytics.hub.session import HUBTrainingSession
            self.session = HUBTrainingSession(model)
            model = self.session.model_file
    
        # Check if Triton Server model
        elif self.is_triton_model(model):
            self.model = model
            self.task = task
            return
    
        # Load or create new YOLO model
        suffix = Path(model).suffix
        if not suffix and Path(model).stem in GITHUB_ASSETS_STEMS:
            model, suffix = Path(model).with_suffix('.pt'), '.pt'  # add suffix, i.e. yolov8n -> yolov8n.pt
        if suffix in ('.yaml', '.yml'):
            self._new(model, task)
        else:
>           self._load(model, task)

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = YOLO(), weights = 'yolov8n.pt', task = None

    def _load(self, weights: str, task=None):
        """
        Initializes a new model and infers the task type from the model head.
    
        Args:
            weights (str): model checkpoint to be loaded
            task (str | None): model task
        """
        suffix = Path(weights).suffix
        if suffix == '.pt':
>           self.model, self.ckpt = attempt_load_one_weight(weights)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\engine\model.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt', device = None, inplace = True, fuse = False

    def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):
        """Loads a single model weights."""
>       ckpt, weight = torch_safe_load(weight)  # load ckpt
                       ^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:628: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

weight = 'yolov8n.pt'

    def torch_safe_load(weight):
        """
        This function attempts to load a PyTorch model with the torch.load() function. If a ModuleNotFoundError is raised,
        it catches the error, logs a warning message, and attempts to install the missing module via the
        check_requirements() function. After installation, the function again attempts to load the model using torch.load().
    
        Args:
            weight (str): The file path of the PyTorch model.
    
        Returns:
            (dict): The loaded PyTorch model.
        """
        from ultralytics.utils.downloads import attempt_download_asset
    
        check_suffix(file=weight, suffix='.pt')
        file = attempt_download_asset(weight)  # search online if missing locally
        try:
            with temporary_modules({
                    'ultralytics.yolo.utils': 'ultralytics.utils',
                    'ultralytics.yolo.v8': 'ultralytics.models.yolo',
                    'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models
>               return torch.load(file, map_location='cpu'), file  # load
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\ultralytics\nn\tasks.py:567: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

f = 'yolov8n.pt', map_location = 'cpu', pickle_module = None
weights_only = True, mmap = False, pickle_load_args = {'encoding': 'utf-8'}
_get_wo_message = <function load.<locals>._get_wo_message at 0x000001E08E787BA0>
weights_only_not_set = True, true_values = ['1', 'y', 'yes', 'true']
force_weights_only_load = False, force_no_weights_only_load = False

    def load(
        f: FileLike,
        map_location: MAP_LOCATION = None,
        pickle_module: Any = None,
        *,
        weights_only: Optional[bool] = None,
        mmap: Optional[bool] = None,
        **pickle_load_args: Any,
    ) -> Any:
        # Reference: https://github.com/pytorch/pytorch/issues/54354
        # The first line of this docstring overrides the one Sphinx generates for the
        # documentation. We need it so that Sphinx doesn't leak `pickle`s path from
        # the build environment (e.g. `<module 'pickle' from '/leaked/path').
    
        """load(f, map_location=None, pickle_module=pickle, *, weights_only=True, mmap=None, **pickle_load_args)
    
        Loads an object saved with :func:`torch.save` from a file.
    
        :func:`torch.load` uses Python's unpickling facilities but treats storages,
        which underlie tensors, specially. They are first deserialized on the
        CPU and are then moved to the device they were saved from. If this fails
        (e.g. because the run time system doesn't have certain devices), an exception
        is raised. However, storages can be dynamically remapped to an alternative
        set of devices using the :attr:`map_location` argument.
    
        If :attr:`map_location` is a callable, it will be called once for each serialized
        storage with two arguments: storage and location. The storage argument
        will be the initial deserialization of the storage, residing on the CPU.
        Each serialized storage has a location tag associated with it which
        identifies the device it was saved from, and this tag is the second
        argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``
        for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.
        :attr:`map_location` should return either ``None`` or a storage. If
        :attr:`map_location` returns a storage, it will be used as the final deserialized
        object, already moved to the right device. Otherwise, :func:`torch.load` will
        fall back to the default behavior, as if :attr:`map_location` wasn't specified.
    
        If :attr:`map_location` is a :class:`torch.device` object or a string containing
        a device tag, it indicates the location where all tensors should be loaded.
    
        Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags
        appearing in the file (keys), to ones that specify where to put the
        storages (values).
    
        User extensions can register their own location tags and tagging and
        deserialization methods using :func:`torch.serialization.register_package`.
    
        See :ref:`layout-control` for more advanced tools to manipulate a checkpoint.
    
        Args:
            f: a file-like object (has to implement :meth:`read`, :meth:`readline`, :meth:`tell`, and :meth:`seek`),
                or a string or os.PathLike object containing a file name
            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage
                locations
            pickle_module: module used for unpickling metadata and objects (has to
                match the :attr:`pickle_module` used to serialize file)
            weights_only: Indicates whether unpickler should be restricted to
                loading only tensors, primitive types, dictionaries
                and any types added via :func:`torch.serialization.add_safe_globals`.
                See :ref:`weights-only` for more details.
            mmap: Indicates whether the file should be mmaped rather than loading all the storages into memory.
                Typically, tensor storages in the file will first be moved from disk to CPU memory, after which they
                are moved to the location that they were tagged with when saving, or specified by ``map_location``. This
                second step is a no-op if the final location is CPU. When the ``mmap`` flag is set, instead of copying the
                tensor storages from disk to CPU memory in the first step, ``f`` is mmaped, which means tensor storages
                will be lazily loaded when their data is accessed.
            pickle_load_args: (Python 3 only) optional keyword arguments passed over to
                :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,
                :attr:`errors=...`.
    
        .. warning::
            :func:`torch.load()` unless `weights_only` parameter is set to `True`,
            uses ``pickle`` module implicitly, which is known to be insecure.
            It is possible to construct malicious pickle data which will execute arbitrary code
            during unpickling. Never load data that could have come from an untrusted
            source in an unsafe mode, or that could have been tampered with. **Only load data you trust**.
    
        .. note::
            When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors
            will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``
            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.
    
        .. note::
            By default, we decode byte strings as ``utf-8``.  This is to avoid a common error
            case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``
            when loading files saved by Python 2 in Python 3.  If this default
            is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how
            these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them
            to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them
            as byte arrays which can be decoded later with ``byte_array.decode(...)``.
    
        Example:
            >>> # xdoctest: +SKIP("undefined filepaths")
            >>> torch.load("tensors.pt", weights_only=True)
            # Load all tensors onto the CPU
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=torch.device("cpu"),
            ...     weights_only=True,
            ... )
            # Load all tensors onto the CPU, using a function
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage,
            ...     weights_only=True,
            ... )
            # Load all tensors onto GPU 1
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location=lambda storage, loc: storage.cuda(1),
            ...     weights_only=True,
            ... )  # type: ignore[attr-defined]
            # Map tensors from GPU 1 to GPU 0
            >>> torch.load(
            ...     "tensors.pt",
            ...     map_location={"cuda:1": "cuda:0"},
            ...     weights_only=True,
            ... )
            # Load tensor from io.BytesIO object
            # Loading from a buffer setting weights_only=False, warning this can be unsafe
            >>> with open("tensor.pt", "rb") as f:
            ...     buffer = io.BytesIO(f.read())
            >>> torch.load(buffer, weights_only=False)
            # Load a module with 'ascii' encoding for unpickling
            # Loading from a module setting weights_only=False, warning this can be unsafe
            >>> torch.load("module.pt", encoding="ascii", weights_only=False)
        """
        torch._C._log_api_usage_once("torch.load")
        DOCS_MESSAGE = (
            "\n\nCheck the documentation of torch.load to learn more about types accepted by default with "
            "weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
        )
    
        def _get_wo_message(message: str) -> str:
            unsafe_global_pattern = r"GLOBAL (\S+) was not an allowed global by default."
            has_unsafe_global = re.search(unsafe_global_pattern, message) is not None
            blocklist_pattern = r"whose module (\S+) is blocked"
            has_blocklist = re.search(blocklist_pattern, message) is not None
            import_pattern = r"(\S+) must be (\S+) to load"
            has_import = re.search(import_pattern, message) is not None
            if has_unsafe_global:
                updated_message = (
                    "Weights only load failed. This file can still be loaded, to do so you have two options, "
                    "\033[1mdo those steps only if you trust the source of the checkpoint\033[0m. "
                    f"\n\t(1) {UNSAFE_MESSAGE}\n\t(2) Alternatively, to load with `weights_only=True` please check "
                    "the recommended steps in the following error message.\n\tWeightsUnpickler error: "
                    + message
                )
            else:
                if has_import:
                    return f"Weights only load failed. {message}\n {UNSAFE_MESSAGE}\n"
                else:
                    updated_message = f"Weights only load failed. {UNSAFE_MESSAGE}\n"
                    if not has_blocklist:
                        updated_message += (
                            "Please file an issue with the following so that we can make "
                            "`weights_only=True` compatible with your use case: WeightsUnpickler error: "
                        )
                updated_message += message
            return updated_message + DOCS_MESSAGE
    
        weights_only_not_set = weights_only is None
    
        if weights_only_not_set:
            weights_only = _default_to_weights_only(pickle_module)
    
        true_values = ["1", "y", "yes", "true"]
        # Add ability to force safe only or non-safe weight loads via environment variables
        force_weights_only_load = (
            os.getenv("TORCH_FORCE_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
        force_no_weights_only_load = (
            os.getenv("TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD", "0") in true_values
        )
    
        if force_weights_only_load and force_no_weights_only_load:
            raise RuntimeError(
                "Only one of `TORCH_FORCE_WEIGHTS_ONLY_LOAD` or `TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD` "
                "should be set, but both were set."
            )
        elif force_weights_only_load:
            weights_only = True
        elif force_no_weights_only_load:
            # TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD can only override if callsite did not explicitly set weights_only
            if weights_only_not_set:
                warnings.warn(
                    "Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the"
                    "`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.",
                    UserWarning,
                    stacklevel=2,
                )
                weights_only = False
    
        if weights_only:
            if pickle_module is not None:
                raise RuntimeError(
                    "Can not safely load weights when explicit pickle_module is specified"
                )
        else:
            if pickle_module is None:
                pickle_module = pickle
    
        # make flipping default BC-compatible
        if mmap is None:
            from torch.utils.serialization import config
    
            mmap = config.load.mmap
    
        _check_dill_version(pickle_module)
    
        if "encoding" not in pickle_load_args.keys():
            pickle_load_args["encoding"] = "utf-8"
    
        with _open_file_like(f, "rb") as opened_file:
            if _is_zipfile(opened_file):
                # The zipfile reader is going to advance the current file position.
                # If we want to actually tail call to torch.jit.load, we need to
                # reset back to the original position.
                orig_position = opened_file.tell()
                overall_storage = None
                with _open_zipfile_reader(opened_file) as opened_zipfile:
                    if _is_torchscript_zip(opened_zipfile):
                        warnings.warn(
                            "'torch.load' received a zip file that looks like a TorchScript archive"
                            " dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to"
                            " silence this warning)",
                            UserWarning,
                        )
                        if weights_only:
                            raise RuntimeError(
                                "Cannot use ``weights_only=True`` with TorchScript archives passed to "
                                "``torch.load``. " + UNSAFE_MESSAGE
                            )
                        opened_file.seek(orig_position)
                        return torch.jit.load(opened_file, map_location=map_location)
                    if mmap:
                        if not _is_path(f):
                            raise ValueError(
                                "f must be a file path in order to use the mmap argument"
                            )
                        size = os.path.getsize(f)
                        if not IS_WINDOWS:
                            shared = get_default_mmap_options() == MAP_SHARED
                        else:
                            shared = False
                        overall_storage = torch.UntypedStorage.from_file(
                            os.fspath(f), shared, size
                        )
                    if weights_only:
                        try:
                            return _load(
                                opened_zipfile,
                                map_location,
                                _weights_only_unpickler,
                                overall_storage=overall_storage,
                                **pickle_load_args,
                            )
                        except pickle.UnpicklingError as e:
>                           raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
E                           _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
E                           	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
E                           	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
E                           	WeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.
E                           
E                           Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.

C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\torch\serialization.py:1529: UnpicklingError
============================== warnings summary ===============================
tests/test_pipeline_video.py::TestObjectDetection::test_yolo_init
tests/test_pipeline_video.py::TestObjectDetection::test_yolo_init
  C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\thop\profile.py:12: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(torch.__version__) < LooseVersion("1.0.0"):

tests/test_pipeline_video.py::TestObjectDetection::test_yolo_init
tests/test_pipeline_video.py::TestObjectDetection::test_yolo_init
  C:\Users\GIGABYTE\AppData\Roaming\Python\Python313\site-packages\thop\profile.py:68: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(torch.__version__) >= LooseVersion("1.1.0"):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/test_pipeline_video.py::TestObjectDetection::test_yolo_init - _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
FAILED tests/test_pipeline_video.py::TestObjectDetection::test_yolo_detect_on_frame
FAILED tests/test_pipeline_video.py::TestObjectDetection::test_classical_player_detector
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_import - Import...
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_init
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_update_with_measurement
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_update_without_measurement
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_kalman_filter_trajectory
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_optical_flow_estimator
FAILED tests/test_pipeline_video.py::TestObjectTracking::test_multi_object_tracker_no_deepsort
FAILED tests/test_pipeline_video.py::TestVisualization::test_heatmap_generator
FAILED tests/test_pipeline_video.py::TestEndToEndPipeline::test_pipeline_import
FAILED tests/test_pipeline_video.py::TestEndToEndPipeline::test_pipeline_short_run
FAILED tests/test_pipeline_video.py::TestEndToEndPipeline::test_pipeline_100_frames
FAILED tests/test_pipeline_video.py::TestIntegration::test_detection_to_tracking
FAILED tests/test_pipeline_video.py::TestIntegration::test_visualization_with_real_detections
================== 16 failed, 38 passed, 4 warnings in 8.79s ==================
