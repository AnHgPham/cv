{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Court Detection & Homography\n",
    "\n",
    "Module 1: Comparing classical (Hough Transform) vs deep learning (CNN keypoint) approaches.\n",
    "\n",
    "Knowledge applied:\n",
    "- Image Processing (color spaces, thresholding, morphology)\n",
    "- Hough Transform\n",
    "- SIFT feature matching\n",
    "- Homography estimation with RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.court_detection import (\n",
    "    ClassicalCourtDetector,\n",
    "    DeepCourtDetector,\n",
    "    SIFTCourtMatcher,\n",
    "    TENNIS_COURT_CORNERS,\n",
    "    transform_points,\n",
    "    draw_court_overlay,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample frame from video\n",
    "VIDEO_PATH = '../data/raw/sample_match.mp4'\n",
    "\n",
    "def get_sample_frame(video_path, frame_idx=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ret else None\n",
    "\n",
    "# Use a test image if video not available\n",
    "if os.path.exists(VIDEO_PATH):\n",
    "    frame = get_sample_frame(VIDEO_PATH)\n",
    "else:\n",
    "    # Create a synthetic court image for testing\n",
    "    frame = np.zeros((720, 1280, 3), dtype=np.uint8)\n",
    "    frame[:] = (70, 130, 70)  # Green court\n",
    "    # Draw white court lines\n",
    "    cv2.rectangle(frame, (200, 100), (1080, 620), (255, 255, 255), 2)\n",
    "    cv2.line(frame, (200, 360), (1080, 360), (255, 255, 255), 2)  # net\n",
    "    cv2.rectangle(frame, (350, 100), (930, 620), (255, 255, 255), 2)  # singles\n",
    "    cv2.line(frame, (350, 230), (930, 230), (255, 255, 255), 2)  # service\n",
    "    cv2.line(frame, (350, 490), (930, 490), (255, 255, 255), 2)  # service\n",
    "    cv2.line(frame, (640, 230), (640, 490), (255, 255, 255), 2)  # center\n",
    "    print('Using synthetic court image')\n",
    "\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Input Frame')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classical Court Detection Pipeline\n",
    "\n",
    "Step-by-step visualization of the classical approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ClassicalCourtDetector()\n",
    "\n",
    "# Step 1-3: Preprocessing (HSV thresholding + morphology)\n",
    "mask = detector.preprocess(frame)\n",
    "\n",
    "# Step 4: Canny edges\n",
    "edges = detector.detect_edges(mask)\n",
    "\n",
    "# Visualize preprocessing steps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Frame')\n",
    "\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "axes[1].set_title('White Line Mask (HSV + Morphology)')\n",
    "\n",
    "axes[2].imshow(edges, cmap='gray')\n",
    "axes[2].set_title('Canny Edges')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5-7: Hough Lines, Classification, Intersections\n",
    "result = detector.detect(frame)\n",
    "\n",
    "# Visualize detected lines\n",
    "line_img = frame.copy()\n",
    "\n",
    "# Draw horizontal lines in blue\n",
    "for line in result['horizontal']:\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(line_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "# Draw vertical lines in red\n",
    "for line in result['vertical']:\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(line_img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# Draw intersections\n",
    "for (ix, iy) in result['intersections']:\n",
    "    cv2.circle(line_img, (int(ix), int(iy)), 8, (0, 255, 0), -1)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.imshow(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Hough Lines: {len(result['horizontal'])} horizontal (blue), \"\n",
    "          f\"{len(result['vertical'])} vertical (red), \"\n",
    "          f\"{len(result['intersections'])} intersections (green)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Horizontal lines: {len(result['horizontal'])}\")\n",
    "print(f\"Vertical lines: {len(result['vertical'])}\")\n",
    "print(f\"Intersection points: {len(result['intersections'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homography Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Compute homography\n",
    "H, detection = detector.detect_and_compute_homography(frame)\n",
    "\n",
    "if H is not None:\n",
    "    print('Homography matrix H:')\n",
    "    print(H)\n",
    "    print()\n",
    "    \n",
    "    # Draw court overlay using inverse homography\n",
    "    H_inv = np.linalg.inv(H)\n",
    "    overlay = draw_court_overlay(frame, H_inv)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Court Overlay (Green = projected court model)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Could not compute homography.')\n",
    "    print('Need at least 4 intersection points matching court corners.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SIFT Feature Matching (Camera Motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate SIFT matching between two frames\n",
    "sift_matcher = SIFTCourtMatcher()\n",
    "\n",
    "# Process first frame\n",
    "H1 = sift_matcher.compute_frame_homography(frame)\n",
    "print(f'SIFT keypoints extracted from frame')\n",
    "print(f'Cumulative homography:\\n{sift_matcher.cumulative_H}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Learning Court Detector\n",
    "\n",
    "CNN-based keypoint detection (requires trained weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning court detector (requires trained weights)\n",
    "# Uncomment after training:\n",
    "#\n",
    "# deep_detector = DeepCourtDetector(\n",
    "#     num_keypoints=14,\n",
    "#     weights_path='../models/court_detector/court_keypoint_best.pt',\n",
    "#     device='cuda',\n",
    "# )\n",
    "# H_deep, keypoints = deep_detector.detect_and_compute_homography(frame)\n",
    "#\n",
    "# # Visualize predicted keypoints\n",
    "# kp_img = frame.copy()\n",
    "# for i, (x, y) in enumerate(keypoints):\n",
    "#     cv2.circle(kp_img, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "#     cv2.putText(kp_img, str(i), (int(x)+5, int(y)-5),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "#\n",
    "# plt.imshow(cv2.cvtColor(kp_img, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('CNN Predicted Court Keypoints')\n",
    "# plt.show()\n",
    "\n",
    "print('Deep court detector ready (uncomment above after training weights)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
